{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a475ea1",
   "metadata": {},
   "source": [
    "# Exercises XP\n",
    "Last Updated: May 26th, 2025\n",
    "\n",
    "### üë©‚Äçüè´ üë©üèø‚Äçüè´ What You‚Äôll learn\n",
    "Identify structured and unstructured data.\n",
    "Convert unstructured data into structured formats.\n",
    "Categorize and utilize different data types in a business context.\n",
    "Learn how to import datasets directly from Kaggle.\n",
    "Understand the process of importing and displaying data from a CSV file using Pandas.\n",
    "Gain skills in fetching and reading JSON data from a URL using Pandas.\n",
    "\n",
    "\n",
    "### üõ†Ô∏è What you will create\n",
    "Classify various data sources.\n",
    "Convert raw data into structured formats.\n",
    "How to import the Titanic dataset from Kaggle and display its initial rows.\n",
    "A script for importing the Iris dataset from a CSV file and displaying its first few rows.\n",
    "How to import JSON data from a URL and display the initial entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3282fe99",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## üåü Exercise 1: Identifying Data Types\n",
    "Below are various data sources. Identify whether each one is an example of structured or unstructured data.\n",
    "\n",
    "A company‚Äôs financial reports stored in an Excel file.\n",
    "Photographs uploaded to a social media platform.\n",
    "A collection of news articles on a website.\n",
    "Inventory data in a relational database.\n",
    "Recorded interviews from a market research study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99995ef8",
   "metadata": {},
   "source": [
    "### Solution:\n",
    "\n",
    "1. **Un fichier Excel de rapports financiers d‚Äôune entreprise** : **Donn√©es structur√©es**\n",
    "2. **Photos sur un r√©seau social** : **Donn√©es non structur√©es**\n",
    "3. **Articles de presse sur un site web** : **Donn√©es non structur√©es**\n",
    "4. **Donn√©es d‚Äôinventaire dans une base de donn√©es relationnelle** : **Donn√©es structur√©es**\n",
    "5. **Enregistrements d‚Äôentretiens d‚Äôune √©tude de march√©** : **Donn√©es non structur√©es**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268b4918",
   "metadata": {},
   "source": [
    "## üåü Exercise 2: Transformation Exercise\n",
    "For each of the following unstructured data sources, propose a method to convert it into structured data. Explain your reasoning.\n",
    "\n",
    "A series of blog posts about travel experiences.\n",
    "Audio recordings of customer service calls.\n",
    "Handwritten notes from a brainstorming session.\n",
    "A video tutorial on cooking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78192267",
   "metadata": {},
   "source": [
    "### Solution:\n",
    "\n",
    "1. **Blogues sur des exp√©riences de voyage**\n",
    "\n",
    "   * **M√©thode**¬†: Utiliser un traitement automatique du langage (NLP) pour extraire des informations cl√©s (lieux, dates, activit√©s) et les organiser dans un tableau.\n",
    "   * **Raison**¬†: Le texte est libre, mais on peut structurer les infos r√©currentes en champs (ex¬†: destination, dur√©e, activit√©).\n",
    "\n",
    "2. **Enregistrements audio d‚Äôappels au service client**\n",
    "\n",
    "   * **M√©thode**¬†: Transcrire l‚Äôaudio en texte, puis analyser le texte pour identifier les th√®mes, les motifs d‚Äôappels, les r√©sultats, etc.\n",
    "   * **Raison**¬†: On obtient alors des cat√©gories et des mots-cl√©s exploitables dans une base de donn√©es.\n",
    "\n",
    "3. **Notes manuscrites d‚Äôune s√©ance de brainstorming**\n",
    "\n",
    "   * **M√©thode**¬†: Scanner puis utiliser la reconnaissance optique de caract√®res (OCR), puis organiser les id√©es en cat√©gories dans un tableau.\n",
    "   * **Raison**¬†: Cela permet de passer du papier √† des listes exploitables informatiquement.\n",
    "\n",
    "4. **Vid√©o tutoriel de cuisine**\n",
    "\n",
    "   * **M√©thode**¬†: Convertir la vid√©o en texte (transcription), puis extraire les √©tapes, ingr√©dients, dur√©es, etc., pour remplir un tableau structur√© (recette, √©tapes, temps).\n",
    "   * **Raison**¬†: On transforme le contenu audiovisuel en donn√©es organis√©es, faciles √† retrouver et analyser.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57ac0a9",
   "metadata": {},
   "source": [
    "## üåü Exercise 3 : Import a file from Kaggle\n",
    "Import the train dataset. Use the train.csv file.\n",
    "Print the first few rows of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78673966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Chemin vers le fichier t√©l√©charg√© depuis Kaggle\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "# Afficher les premi√®res lignes du DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a15c3e8",
   "metadata": {},
   "source": [
    "## üåü Exercise 4: Importing a CSV File\n",
    "Use the Iris Dataset CSV.\n",
    "\n",
    "Download the Iris dataset CSV file and place it in the same directory as your Jupyter Notebook.\n",
    "Import the CSV file using Pandas.\n",
    "Display the first five rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84dcae67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
      "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
      "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
      "4   5            5.0           3.6            1.4           0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Importation du fichier Iris\n",
    "df = pd.read_csv('iris.csv')\n",
    "\n",
    "# Affichage des 5 premi√®res lignes\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892e9fca",
   "metadata": {},
   "source": [
    "## üåü Exercise 5 : Export a dataframe to excel format and JSON format.\n",
    "Create a simple dataframe.\n",
    "Export the dataframe to an excel file.\n",
    "Export the dataframe to a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04dcad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cr√©ation d'un DataFrame simple\n",
    "data = {'Nom': ['Alice', 'Bob', 'Charlie'], '√Çge': [25, 30, 22]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Exporter en format Excel\n",
    "df.to_excel('exemple.xlsx', index=False)\n",
    "\n",
    "# Exporter en format JSON\n",
    "df.to_json('exemple.json', orient='records', force_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580a5693",
   "metadata": {},
   "source": [
    "## üåü Exercise 6: Reading JSON Data\n",
    "Use a sample JSON dataset\n",
    "\n",
    "Import the JSON data from the provided URL.\n",
    "Use Pandas to read the JSON data.\n",
    "Display the first five entries of the data.üåü Exercise 6: Reading JSON Data\n",
    "Use a sample JSON dataset\n",
    "\n",
    "Import the JSON data from the provided URL.\n",
    "Use Pandas to read the JSON data.\n",
    "Display the first five entries of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d88a9ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  id                                              title  \\\n",
      "0       1   1  sunt aut facere repellat provident occaecati e...   \n",
      "1       1   2                                       qui est esse   \n",
      "2       1   3  ea molestias quasi exercitationem repellat qui...   \n",
      "3       1   4                               eum et est occaecati   \n",
      "4       1   5                                 nesciunt quas odio   \n",
      "\n",
      "                                                body  \n",
      "0  quia et suscipit\\nsuscipit recusandae consequu...  \n",
      "1  est rerum tempore vitae\\nsequi sint nihil repr...  \n",
      "2  et iusto sed quo iure\\nvoluptatem occaecati om...  \n",
      "3  ullam et saepe reiciendis voluptatem adipisci\\...  \n",
      "4  repudiandae veniam quaerat sunt sed\\nalias aut...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Remplace l‚ÄôURL ci-dessous par celle fournie dans l‚Äôexercice\n",
    "url = 'https://github.com/devtlv/Datasets-DA-Bootcamp-2-/raw/refs/heads/main/Week%204%20-%20Data%20Understanding/W4D3%20-%20Importing%20Data,%20Exporting%20D/posts.zip'\n",
    "\n",
    "# Importation des donn√©es JSON\n",
    "df = pd.read_json(url)\n",
    "\n",
    "# Affichage des 5 premi√®res entr√©es\n",
    "print(df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
