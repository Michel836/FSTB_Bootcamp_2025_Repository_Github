{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b516725",
   "metadata": {},
   "source": [
    "Exercises XP Ninja\n",
    "Last Updated: January 8th, 2024\n",
    "\n",
    "What you will learn\n",
    "how to train a logistic regression model\n",
    "how to evaluate your model with metricq\n",
    "\n",
    "\n",
    "What you will create\n",
    "a script to implement Python functions to calculate Accuracy, Precision, Recall, and F1-Score from scratch.\n",
    "\n",
    "\n",
    "Exercise 1 : Evaluation Metrics Implementation\n",
    "Objective:\n",
    "Implement Python functions to calculate Accuracy, Precision, Recall, and F1-Score from scratch.\n",
    "\n",
    "Dataset:\n",
    "Use any binary classification dataset, for example, the Breast Cancer Wisconsin (Diagnostic) dataset available in scikit-learn or any other binary classification dataset of your choice.\n",
    "\n",
    "Tasks:\n",
    "Split the dataset into training and test sets.\n",
    "Train a simple classification model (like Logistic Regression) on the training set.\n",
    "Make predictions on the test set.\n",
    "Write functions to calculate Accuracy, Precision, Recall, and F1-Score using the confusion matrix components (TP, TN, FP, FN).\n",
    "Evaluate your model using these metrics and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763aa3dd",
   "metadata": {},
   "source": [
    "üìå Cellule 1 ‚Äì Import des biblioth√®ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b24e7cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des biblioth√®ques n√©cessaires\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713b1463",
   "metadata": {},
   "source": [
    "üìå Cellule 2 ‚Äì Chargement du jeu de donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd2010bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme des donn√©es : (569, 30)\n",
      "Classes : [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Chargement du jeu de donn√©es Breast Cancer (classification binaire)\n",
    "data = load_breast_cancer()\n",
    "X = data.data       # variables explicatives\n",
    "y = data.target     # √©tiquettes (0 = maligne, 1 = b√©nigne)\n",
    "\n",
    "# Affichage rapide de la forme des donn√©es\n",
    "print(\"Forme des donn√©es :\", X.shape)\n",
    "print(\"Classes :\", np.unique(y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5090e8",
   "metadata": {},
   "source": [
    "üìå Cellule 3 ‚Äì S√©paration en train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4041aa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille train : 455\n",
      "Taille test : 114\n"
     ]
    }
   ],
   "source": [
    "# Division du jeu de donn√©es : 80% entra√Ænement, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Taille train :\", X_train.shape[0])\n",
    "print(\"Taille test :\", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac7de2f",
   "metadata": {},
   "source": [
    "üìå Cellule 4 ‚Äì Entra√Ænement du mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95e3109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation et entra√Ænement d‚Äôun mod√®le de r√©gression logistique\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Pr√©dictions sur le jeu de test\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05412f0",
   "metadata": {},
   "source": [
    "üìå Cellule 5 ‚Äì Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cff3b327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vrai n√©gatifs (TN): 39\n",
      "Faux positifs (FP): 4\n",
      "Faux n√©gatifs (FN): 1\n",
      "Vrai positifs (TP): 70\n"
     ]
    }
   ],
   "source": [
    "# Cr√©ation de la matrice de confusion : [TN, FP, FN, TP]\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "print(f\"Vrai n√©gatifs (TN): {tn}\")\n",
    "print(f\"Faux positifs (FP): {fp}\")\n",
    "print(f\"Faux n√©gatifs (FN): {fn}\")\n",
    "print(f\"Vrai positifs (TP): {tp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d622209",
   "metadata": {},
   "source": [
    "üìå Cellule 6 ‚Äì Fonctions de calcul des m√©triques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e03316ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul manuel des m√©triques d'√©valuation\n",
    "\n",
    "def accuracy(tp, tn, fp, fn):\n",
    "    return (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "def precision(tp, fp):\n",
    "    return tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "\n",
    "def recall(tp, fn):\n",
    "    return tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "\n",
    "def f1_score(prec, rec):\n",
    "    return 2 * (prec * rec) / (prec + rec) if (prec + rec) != 0 else 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0e3323",
   "metadata": {},
   "source": [
    "üìå Cellule 7 ‚Äì √âvaluation du mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb401803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  : 0.9561\n",
      "Precision : 0.9459\n",
      "Recall    : 0.9859\n",
      "F1-Score  : 0.9655\n"
     ]
    }
   ],
   "source": [
    "# Application des fonctions sur les r√©sultats\n",
    "acc = accuracy(tp, tn, fp, fn)\n",
    "prec = precision(tp, fp)\n",
    "rec = recall(tp, fn)\n",
    "f1 = f1_score(prec, rec)\n",
    "\n",
    "# Affichage\n",
    "print(f\"Accuracy  : {acc:.4f}\")\n",
    "print(f\"Precision : {prec:.4f}\")\n",
    "print(f\"Recall    : {rec:.4f}\")\n",
    "print(f\"F1-Score  : {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2566b5",
   "metadata": {},
   "source": [
    "Ces r√©sultats montrent que :\n",
    "\n",
    "* **Accuracy (95.61‚ÄØ%)** : Le mod√®le est globalement tr√®s pr√©cis sur tous les cas.\n",
    "* **Precision (94.59‚ÄØ%)** : Parmi les cas pr√©dits comme positifs (b√©nins), 94.59‚ÄØ% sont r√©ellement corrects ‚Üí peu de faux positifs.\n",
    "* **Recall (98.59‚ÄØ%)** : Le mod√®le capte presque tous les vrais cas positifs ‚Üí tr√®s peu de faux n√©gatifs.\n",
    "* **F1-Score (96.55‚ÄØ%)** : Excellent √©quilibre entre pr√©cision et rappel.\n",
    "\n",
    "üí° **Interpr√©tation** : Ce mod√®le est **tr√®s fiable** pour un cas m√©dical o√π il est crucial de **ne pas rater un cas r√©el (recall √©lev√©)**, tout en **limitant les fausses alertes (bonne pr√©cision)**.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
