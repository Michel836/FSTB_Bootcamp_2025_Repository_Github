{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58dce448",
   "metadata": {},
   "source": [
    "# Exercises XP Ninja\n",
    "Last Updated: January 15th, 2024\n",
    "\n",
    "## What will you learn\n",
    "Understanding Convolutional Neural Networks (CNNs): You will gain a fundamental understanding of how CNNs work, their architecture, and their application in machine learning.\n",
    "Data Preprocessing for Neural Networks: Learn how to import and preprocess data for neural networks, including encoding labels and scaling features, which are critical steps for preparing data for training.\n",
    "Model Building with Keras: Acquire hands-on experience in building neural network models using Keras, a high-level neural networks API.\n",
    "Sequential Model Creation: Understand how to create neural network models using the .sequential() method in Keras, which is essential for stacking layers in a neural network.\n",
    "Compiling and Training Neural Networks: Learn how to compile a neural network with appropriate loss functions and optimizers, and how to train the model on a dataset.\n",
    "Model Evaluation: Develop skills to evaluate the performance of a neural network model by analyzing its loss and accuracy.\n",
    "\n",
    "\n",
    "## What will you create\n",
    "Convolutional Neural Network Model: You will create a CNN model using Keras to classify data from the provided dataset. This model will serve as a practical example of implementing CNNs in a real-world scenario.\n",
    "Data Preprocessing Pipeline: A complete pipeline for data preprocessing tailored for neural networks, including label encoding and feature scaling.\n",
    "Trained and Evaluated Model: By the end of the exercise, you will have a fully trained CNN model with evaluated metrics, giving you insights into its performance.\n",
    "Comprehensive Understanding of CNN Workflow: You will have a clear understanding of the end-to-end process of building, training, and evaluating CNNs, which can be applied to other datasets and problems in machine learning.\n",
    "\n",
    "\n",
    "## Exercise 1 : Create a simple Convolutionnal Neural networks (CNN)\n",
    "### Instructions\n",
    "First read about this lesson about CNN : Here\n",
    "and use this tutorial to do this exercise : tutorial\n",
    "\n",
    "Import required libraries including Keras\n",
    "Load this dataset\n",
    "encode the label and scale the feature\n",
    "Split the dataset\n",
    "Create Neural Network Model using .sequential()\n",
    "Compile and Train model\n",
    "Evaluate model’s loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66f82845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chume\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3431 - loss: 1.8459 - val_accuracy: 0.4944 - val_loss: 1.4336\n",
      "Epoch 2/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5176 - loss: 1.3554 - val_accuracy: 0.5628 - val_loss: 1.2756\n",
      "Epoch 3/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5641 - loss: 1.2333 - val_accuracy: 0.5718 - val_loss: 1.2444\n",
      "Epoch 4/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5980 - loss: 1.1419 - val_accuracy: 0.5795 - val_loss: 1.1996\n",
      "Epoch 5/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6282 - loss: 1.0706 - val_accuracy: 0.6010 - val_loss: 1.1594\n",
      "Epoch 6/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6474 - loss: 1.0133 - val_accuracy: 0.6126 - val_loss: 1.1244\n",
      "Epoch 7/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6661 - loss: 0.9727 - val_accuracy: 0.6175 - val_loss: 1.1041\n",
      "Epoch 8/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6775 - loss: 0.9309 - val_accuracy: 0.6298 - val_loss: 1.0687\n",
      "Epoch 9/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6926 - loss: 0.8897 - val_accuracy: 0.6207 - val_loss: 1.1034\n",
      "Epoch 10/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7010 - loss: 0.8679 - val_accuracy: 0.6285 - val_loss: 1.0833\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 0.6343 - loss: 1.0766\n",
      "Loss : 1.0871 | Accuracy : 0.6349\n"
     ]
    }
   ],
   "source": [
    "# 1. Import des bibliothèques\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10  # Exemple de dataset image\n",
    "\n",
    "# 2. Chargement du dataset (exemple avec CIFAR-10)\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# 3. Encodage des labels et mise à l’échelle des features\n",
    "encoder = LabelEncoder()\n",
    "y_train_enc = encoder.fit_transform(y_train.ravel())\n",
    "y_test_enc = encoder.transform(y_test.ravel())\n",
    "y_train_cat = to_categorical(y_train_enc)\n",
    "y_test_cat = to_categorical(y_test_enc)\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# 4. Création du modèle CNN\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=x_train.shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))  # 10 classes CIFAR-10\n",
    "\n",
    "# 5. Compilation et entraînement du modèle\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train_cat, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# 6. Évaluation du modèle\n",
    "loss, accuracy = model.evaluate(x_test, y_test_cat)\n",
    "print(f\"Loss : {loss:.4f} | Accuracy : {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdd97ef",
   "metadata": {},
   "source": [
    "Le modèle CNN fonctionne correctement. Voici l’analyse :\n",
    "\n",
    "### Résultats finaux :\n",
    "\n",
    "* **Loss (test)** : \\~1.08\n",
    "* **Accuracy (test)** : \\~63.4 %\n",
    "\n",
    "### Interprétation :\n",
    "\n",
    "* Ton modèle progresse bien sur les 10 epochs (accuracy passe de 34 % à 70 % en entraînement).\n",
    "* L'accuracy sur la validation et le test est cohérente (\\~63 %), ce qui indique un modèle **pas overfitté**.\n",
    "* Pour CIFAR-10, ce score est **acceptable** pour un modèle simple. Avec plus de couches (ou Dropout, BatchNorm), tu peux facilement dépasser les **75-80 %**.\n",
    "\n",
    "### Améliorations possibles :\n",
    "\n",
    "* Ajouter une deuxième couche `Conv2D` et `MaxPooling2D`\n",
    "* Utiliser `Dropout()` pour régulariser\n",
    "* Augmenter `epochs` ou utiliser `EarlyStopping`\n",
    "* Ajouter `BatchNormalization`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e618c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "y_train_cat = to_categorical(y_train, num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb52d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_train = tf.image.resize(x_train, [32, 32])\n",
    "x_train = tf.image.grayscale_to_rgb(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f31fa611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "750/750 [==============================] - 68s 90ms/step - loss: 0.1586 - accuracy: 0.9513 - val_loss: 0.0544 - val_accuracy: 0.9838\n",
      "Epoch 2/3\n",
      "750/750 [==============================] - 71s 95ms/step - loss: 0.0612 - accuracy: 0.9806 - val_loss: 0.0456 - val_accuracy: 0.9870\n",
      "Epoch 3/3\n",
      "750/750 [==============================] - 71s 95ms/step - loss: 0.0469 - accuracy: 0.9850 - val_loss: 0.0376 - val_accuracy: 0.9878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2993e8ccfd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Bloc 1\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Bloc 2\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Bloc final\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compilation\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraînement\n",
    "model.fit(x_train, y_train_cat, epochs=3, batch_size=64, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bc18ca",
   "metadata": {},
   "source": [
    "Le modèle fonctionne bien\n",
    "\n",
    "Voici un résumé rapide :\n",
    "\n",
    "* **Précision entraînement** : 98.5 %\n",
    "* **Précision validation** : 98.78 %\n",
    "* **Perte en baisse constante** → bon apprentissage, pas de surapprentissage visible en 3 époques\n",
    "\n",
    "Si tu veux améliorer encore :\n",
    "\n",
    "* Augmente le nombre d’époques\n",
    "* Ajoute de la régularisation (Dropout, etc.)\n",
    "* Essaie des architectures plus complexes si besoin\n",
    "\n",
    "Mais déjà, très bon résultat sur MNIST.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e94fa44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
